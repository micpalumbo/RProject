for(i in seq_along(dfs)){
dfs[[i]]$date <- as.Date(paste(dfs[[i]]$year, dfs[[i]]$mo, dfs[[i]]$day, sep = "/"), format = "%Y/%m/%d")
}
# create epiweek variable
library(data.table)
for(i in seq_along(dfs)){
dfs[[i]]$epiweek <- week(dfs[[i]]$date)
}
# creating new variables that summarize the variables on a weekly basis
library(plyr)
byweek <- NULL
for(i in seq_along(dfs)){
byweek[[i]] <- ddply(dfs[[i]], .(epiweek, year), summarize, raint=sum(raint), tavg=mean(tavg),
rh=mean(rh), sd=mean(sd), psfc=mean(psfc))
}
# put these weekly summary tables into dataframe form
byweekdf <- NULL
for(i in seq_along(byweek)){
byweekdf[[i]] <- as.data.frame(byweek[[i]])
}
# so we now have 142 byweek dataframes one for each districts dataset that contain the weekly variables
# this is what we want to combine with the other datasets inc and int
# first have to combine the 142 byweek datasets into one dataset
weather <- do.call("rbind", byweekdf)
## Save combined weather data so I don't have to run this all again every time ##
write.csv(weather, "~/Documents/CU AMC Fall 2017/BIOS6640/Project/weather.csv")
rm(list = c("byweek", "byweekdf", "dfs", "distlist", "GetMe", "i", "links", "url", "wanted"))
head(weather)
## IMPORT POLYGON FILE
library(maptools)
poly1 <- readShapePoly("/Users/Michaela/Documents/CU AMC Fall 2017/BIOS6640/Project/Moz_admin2.shp", IDvar="DISTCODE")
weather <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/weather.csv")
rm(list = c("inc", "int", "poly1", "weather"))
inc <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/incidence.csv")
int <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/intervention.csv")
weather <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/weather.csv")
poly1 <- readShapePoly("/Users/Michaela/Documents/CU AMC Fall 2017/BIOS6640/Project/Moz_admin2.shp", IDvar="DISTCODE")
weather$X <- NULL
## CREATE LAG VARIABLES FOR WEATHER DATASET
# 2 week lag
weather2 < - weather
## CREATE LAG VARIABLES FOR WEATHER DATASET
# 2 week lag
weather2 <- weather
weather2$epiweek <- weather2$epiweek + 2
names(weather2) <- c("epiweek2", "year2", "raint2", "tavg2", "rh2", "sd2", "psfc2")
int$DISTCODE
length(unique(int$DISTCODE))
length(unique(inc$DISTCODE))
# 2 week lag for epiweek
weather$epiweekl2 <- weather$epiweek + 2
# 4 week lag for epiweek
weather$epiweekl4 <- weather$epiweek + 4
# 6 week lag for epiweek
weather$epiweekl6 <- weather$epiweek + 6
# 8 week lag for epiweek
weather$epiweekl8 <- weather$epiweek + 8
weather$epiweekl6 <- NULL
# create indicator variable for weather ITNS were given as intervention
intITN <- int[, c(1, 4:5)]
intITN$ITNind <- ifelse(is.na(intITN$ITNyear), 0, 1)
# create indicator variable for weather IRS was given as intervention
intIRS <- int[, c(1:3)]
intIRS$IRSind <- ifelse(is.na(intIRS$IRSyear), 0, 1)
# merge these updatated intervention datasets with incidence datasets
datm1 <- merge(inc, intITN, by.x = c("Epiyear", "Epiweek", "DISTCODE"),
by.y = c("ITNyear", "ITNepiWeek", "DISTCODE"))
# merge these updatated intervention datasets with incidence datasets
datm1 <- merge(inc, intITN, by.x = c("Epiyear", "Epiweek", "DISTCODE"),
by.y = c("ITNyear", "ITNepiWeek", "DISTCODE"), all = TRUE)
datm2 <- merge(datm1, intIRS, by.x = c("Epiyear", "Epiweek", "DISTCODE"),
by.y = c("IRSyear", "IRSepiWeek", "DISTCODE"), all = TRUE)
# change the intervention indicator variable NAs to 0s
datm2$ITNind <- ifelse(is.na(datm2$ITNind), 0, 1)
datm2$IRSind <- ifelse(is.na(datm2$IRSind), 0, 1)
rm(list = c("datm1", "inc", "int", "intIRS", "intITN", "weather2"))
rm(weather)
# base url for all txt files
# htmlParse turns URL into an R object
url <- htmlParse("http://rap.ucar.edu/staff/monaghan/colborn/mozambique/daily/v2/")
# get specific links that match criterion
links <- xpathSApply(url, "//a/@href")
# recognizing patterns that have the end of the txt file name we're looking for
wanted <- links[grepl("*_fldas_daily_20100101-20170724.txt", links)]
# paste base url followed by the rest of the link we wante for each text file
GetMe <- paste("http://rap.ucar.edu/staff/monaghan/colborn/mozambique/daily/v2/", wanted, sep = "")
# read in each of the data frames from each text file
# note lapply creates a list object so will have list of all the 142 dataframes
dfs <- lapply(seq_along(GetMe),
function(x) read.table(GetMe[x], skip=3, header = FALSE, sep = '', stringsAsFactors = FALSE, dec = "."))
# add column names to the data frames
for(i in seq_along(dfs)){
colnames(dfs[[i]]) <- c("year", "mo", "day", "raint", "tavg", "rh", "sd", "psfc")
}
# get list of district names from links to datasets for each of the 142 districts
distlist <- as.list(gsub("_.{3}_fldas_daily_20100101-20170724.txt", "", links))
distlist <- gsub("_", "", distlist) # replace underscores with nothing, now it is a character vector
# first 6 elements returned are not district names
distlist <- distlist[6:147] # now have list of 142 district names
# get list of district names from links to datasets for each of the 142 districts
distlist <- as.list(gsub("_.{3}_fldas_daily_20100101-20170724.txt", "", links))
distlist <- gsub("_", " ", distlist) # replace underscores with space, now it is a character vector
# first 6 elements returned are not district names
distlist <- distlist[6:147] # now have list of 142 district names
# add column for district name using Map to apply to all dataframes in list
dfs <- Map(cbind, dfs, District = distlist)
# create new date variable by combining day, month, and year
for(i in seq_along(dfs)){
dfs[[i]]$date <- as.Date(paste(dfs[[i]]$year, dfs[[i]]$mo, dfs[[i]]$day, sep = "/"), format = "%Y/%m/%d")
}
for(i in seq_along(dfs)){
dfs[[i]]$epiweek <- week(dfs[[i]]$date)
}
byweek <- NULL
for(i in seq_along(dfs)){
byweek[[i]] <- ddply(dfs[[i]], .(epiweek, year), summarize, raint=sum(raint), tavg=mean(tavg),
rh=mean(rh), sd=mean(sd), psfc=mean(psfc))
}
# add the district names column
byweek <- Map(cbind, byweek, district = distlist)
# put these weekly summary tables into dataframe form
byweekdf <- NULL
for(i in seq_along(byweek)){
byweekdf[[i]] <- as.data.frame(byweek[[i]])
}
# so we now have 142 byweek dataframes
# one for each districts dataset that contain the weekly variables
# this is what we want to combine with the other datasets inc and int
# first have to combine the 142 byweek datasets into one dataset
weather <- do.call("rbind", byweek)
head(weather)
length(unique(weather$district))
## Save combined weather data so I don't have to run this all again every time ##
write.csv(weather, "~/Documents/CU AMC Fall 2017/BIOS6640/Project/weather.csv")
rm(list = c("byweek", "byweekdf", "datm2", "dfs", "poly1", "weather", "distlist", "GetMe", "i", "links", "url", "wanted"))
inc <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/incidence.csv")
int <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/intervention.csv")
weather <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/weather.csv")
weather$X <- NULL # remove unnecessary X column
poly1 <- readShapePoly("/Users/Michaela/Documents/CU AMC Fall 2017/BIOS6640/Project/Moz_admin2.shp", IDvar="DISTCODE")
# 2 week lag for epiweek
weather$epiweekl2 <- weather$epiweek + 2
# 4 week lag for epiweek
weather$epiweekl4 <- weather$epiweek + 4
# 8 week lag for epiweek
weather$epiweekl8 <- weather$epiweek + 8
# create indicator variable for weather ITNS were given as intervention
intITN <- int[, c(1, 4:5)]
intITN$ITNind <- ifelse(is.na(intITN$ITNyear), 0, 1)
# create indicator variable for weather IRS was given as intervention
intIRS <- int[, c(1:3)]
intIRS$IRSind <- ifelse(is.na(intIRS$IRSyear), 0, 1)
# merge these updatated intervention datasets with incidence datasets
datm1 <- merge(inc, intITN, by.x = c("Epiyear", "Epiweek", "DISTCODE"),
by.y = c("ITNyear", "ITNepiWeek", "DISTCODE"), all = TRUE)
datm2 <- merge(datm1, intIRS, by.x = c("Epiyear", "Epiweek", "DISTCODE"),
by.y = c("IRSyear", "IRSepiWeek", "DISTCODE"), all = TRUE)
# change the intervention indicator variable NAs to 0s
datm2$ITNind <- ifelse(is.na(datm2$ITNind), 0, 1)
datm2$IRSind <- ifelse(is.na(datm2$IRSind), 0, 1)
# MERGE WITH WEATHER DATA
datm3 <- merge(datm2, weather, by.x = c("District", "Epiweek", "Epiyear"),
by.y = c("district", "epiweek", "year"))
# create an incidence variable
datm3$incid <- datm3$cases/datm3$u5total*1000
## Save merged data as csv so don't have to run all this again ##
write.csv(datm3, "~/Documents/CU AMC Fall 2017/BIOS6640/Project/CleanMerged.csv")
rm(list = ls())
# load cleaned and merged final dataset
dat <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/CleanMerged.csv")
# load polygon file
poly1 <- readShapePoly("/Users/Michaela/Documents/CU AMC Fall 2017/BIOS6640/Project/Moz_admin2.shp", IDvar="DISTCODE")
dat$X <- NULL
rm(list = ls())
# load cleaned and merged dataset
datm <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/CleanMerged.csv")
# 51876 observations?
sum(datm$IRSind)
sum(datm$INTind)
sum(datm$ITNind)
min(datm$Epiyear)
# create time column
datm$time <- (datm$Epiyear-2010)
# create time column
datm$time <- (datm$Epiyear-2010)*12 + datm$Epiweek
25/24
24/25
0.25/24
0.4/96
# make difference from IRS intervention with current data
datm2 <- NULL
for(i in levels(datm$District)){
df <- subset(datm$District %in% i)
timeIRS <- df$time[df$IRSind==1]
df[, "decayIRS"] <- NA
if(length(timeIRS)==1){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeIRS){
df[j,]$decayIRS <- df[j,]$time - timeIRS
}
}
} else if(length(timeIRS)==2){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeIRS[1] & df[j,]$time < timeIRS[2]){
df$decayIRS <- df[j,]$time - timeIRS[1]
} else if(df[j,]$time >= timeIRS[2]){
df$decayIRS <- df[j,]$time - timeIRS[2]
} else{
}
}
} else{
}
datm2 <- rbind(datm2, df)
}
for(i in levels(datm$District)){
df <- subset(datm, datm$District %in% i)
timeIRS <- df$time[df$IRSind==1]
df[, "decayIRS"] <- NA
if(length(timeIRS)==1){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeIRS){
df[j,]$decayIRS <- df[j,]$time - timeIRS
}
}
} else if(length(timeIRS)==2){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeIRS[1] & df[j,]$time < timeIRS[2]){
df$decayIRS <- df[j,]$time - timeIRS[1]
} else if(df[j,]$time >= timeIRS[2]){
df$decayIRS <- df[j,]$time - timeIRS[2]
} else{
}
}
} else{
}
datm2 <- rbind(datm2, df)
}
sum(datm2$IRS)
sum(datm2$ITN)
# make difference from ITN intervention with current data
# change all datm2 to datm3 and all datm to datm2 and all IRS to ITN
datm3 <- NULL
for(i in levels(datm2$District)){
df <- subset(datm2, datm2$District %in% i)
timeITN <- df$time[df$ITNind==1]
df[, "decayITN"] <- NA
if(length(timeITN)==1){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeITN){
df[j,]$decayITN <- df[j,]$time - timeITN
}
}
} else if(length(timeITN)==2){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeITN[1] & df[j,]$time < timeITN[2]){
df$decayITN <- df[j,]$time - timeITN[1]
} else if(df[j,]$time >= timeITN[2]){
df$decayITN <- df[j,]$time - timeITN[2]
} else{
}
}
} else{
}
datm3 <- rbind(datm3, df)
}
summary(datm3)
51876-20437
# save this final dataset
write.csv(datm3, "~/Documents/CU AMC Fall 2017/BIOS6640/Project/FinalData.csv")
rm(list = ls())
# load final dataset
dat <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/FinalData.csv")
dat$X <- NULL # unnecessary X column
dat$X.1 <- NULL
# looked at lecture 17 notes R script notes on poisson regression models
library(lme4)
fit1 <- glmer(cases ~ raint + tavg + epiweek + decayIRS + decayITN + Region, ~1|DISTCODE,
data = dat, family = poisson(link = "log"))
fit1 <- glmer(cases ~ raint + tavg + epiweek + decayIRS + decayITN + Region + (1|DISTCODE),
data = dat, family = poisson(link = "log"))
fit1 <- glmer(cases ~ raint + tavg + Epiweek + decayIRS + decayITN + Region + (1|DISTCODE),
data = dat, family = poisson(link = "log"))
# load cleaned and merged dataset
datm <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/CleanMerged.csv")
datm$X <- NULL # unnecessary X column
# create time column
datm$time <- (datm$Epiyear-2010)*12 + datm$Epiweek
# make difference from IRS intervention with current data
datm2 <- NULL
for(i in levels(datm$District)){
df <- subset(datm, datm$District %in% i)
timeIRS <- df$time[df$IRSind==1]
df[, "decayIRS"] <- NA
if(length(timeIRS)==1){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeIRS){
df[j,]$decayIRS <- df[j,]$time - timeIRS
}
}
} else if(length(timeIRS)==2){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeIRS[1] & df[j,]$time < timeIRS[2]){
df$decayIRS <- df[j,]$time - timeIRS[1]
} else if(df[j,]$time >= timeIRS[2]){
df$decayIRS <- df[j,]$time - timeIRS[2]
} else{
}
}
} else{
}
datm2 <- rbind(datm2, df)
}
# make difference from ITN intervention with current data
# change all datm2 to datm3 and all datm to datm2 and all IRS to ITN
datm3 <- NULL
for(i in levels(datm2$District)){
df <- subset(datm2, datm2$District %in% i)
timeITN <- df$time[df$ITNind==1]
df[, "decayITN"] <- NA
if(length(timeITN)==1){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeITN){
df[j,]$decayITN <- df[j,]$time - timeITN
}
}
} else if(length(timeITN)==2){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeITN[1] & df[j,]$time < timeITN[2]){
df$decayITN <- df[j,]$time - timeITN[1]
} else if(df[j,]$time >= timeITN[2]){
df$decayITN <- df[j,]$time - timeITN[2]
} else{
}
}
} else{
}
datm3 <- rbind(datm3, df)
}
## mutliply differnce by decay rate and subtract from 1
# IRS
# 75% protection 6 months after start (24 weeks)
0.25/24
24*4
# ITN
# 60% protection 24 months after start (96 weeks)
0.4/96
datm3$decayIRS <- 1 - datm3$decayIRS*(0.25/24)
datm3$decayITN <- 1 - datm3$decayITN*(0.4/96)
# save this final dataset
write.csv(datm3, "~/Documents/CU AMC Fall 2017/BIOS6640/Project/FinalData.csv")
rm(list = ls())
# load final dataset
dat <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/FinalData.csv")
dat$X <- NULL # unnecessary X column
# looked at lecture 17 notes R script notes on poisson regression models
library(lme4)
fit1 <- glmer(cases ~ raint + tavg + Epiweek + decayIRS + decayITN + Region + (1|DISTCODE),
data = dat, family = poisson(link = "log"))
fit2 <- glmer(cases ~  Epiweek + decayIRS + decayITN  + (1|DISTCODE),
data = dat, family = poisson(link = "log"))
fit2 <- glmer(cases ~ decayIRS + decayITN  + (1|DISTCODE),
data = dat, family = poisson(link = "log"))
summary(fit2)
inc <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/incidence.csv")
int <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/intervention.csv")
weather <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/weather.csv")
weather$X <- NULL # remove unnecessary X column
# ----------------------------------------------------- #
# don't know if need sepearate dataset for each lag
# might need to uncomment this code and comment out the code above and create new merged data
weather2 <- weather
weather2$epiweek <- weather2$epiweek + 2
names(weather2) <- c("epiweek2", "year2", "raint2", "tavg2", "rh2", "sd2", "psfc2")
weather4 <- weather
weather4$epiweek <- weather4$epiweek + 4
names(weather4) <- c("epiweek4", "year4", "raint4", "tavg4", "rh4", "sd4", "psfc4")
weather8 <- weather
weather8$epiweek <- weather8$epiweek + 8
names(weather8) <- c("epiweek8", "year8", "raint8", "tavg8", "rh8", "sd8", "psfc8")
# create indicator variable for weather ITNS were given as intervention
intITN <- int[, c(1, 4:5)]
intITN$ITNind <- ifelse(is.na(intITN$ITNyear), 0, 1)
# create indicator variable for weather IRS was given as intervention
intIRS <- int[, c(1:3)]
intIRS$IRSind <- ifelse(is.na(intIRS$IRSyear), 0, 1)
# merge these updatated intervention datasets with incidence datasets
datm1 <- merge(inc, intITN, by.x = c("Epiyear", "Epiweek", "DISTCODE"),
by.y = c("ITNyear", "ITNepiWeek", "DISTCODE"), all = TRUE)
datm2 <- merge(datm1, intIRS, by.x = c("Epiyear", "Epiweek", "DISTCODE"),
by.y = c("IRSyear", "IRSepiWeek", "DISTCODE"), all = TRUE)
# change the intervention indicator variable NAs to 0s
datm2$ITNind <- ifelse(is.na(datm2$ITNind), 0, 1)
datm2$IRSind <- ifelse(is.na(datm2$IRSind), 0, 1)
names(weather2) <- c("epiweek2", "year2", "raint2", "tavg2", "rh2", "sd2", "psfc2", "district2")
names(weather4) <- c("epiweek4", "year4", "raint4", "tavg4", "rh4", "sd4", "psfc4", "district4")
names(weather8) <- c("epiweek8", "year8", "raint8", "tavg8", "rh8", "sd8", "psfc8", "district8")
rm(list=ls())
# load cleaned and merged dataset
datm <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/CleanMerged.csv")
datm$X <- NULL # unnecessary X column
## create time column
datm$time <- (datm$Epiyear-2010)*52 + datm$Epiweek
## make difference from IRS intervention with current data
datm2 <- NULL
for(i in levels(datm$District)){
df <- subset(datm, datm$District %in% i)
timeIRS <- df$time[df$IRSind==1]
df[, "decayIRS"] <- NA
if(length(timeIRS)==1){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeIRS){
df[j,]$decayIRS <- df[j,]$time - timeIRS
}
}
} else if(length(timeIRS)==2){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeIRS[1] & df[j,]$time < timeIRS[2]){
df$decayIRS <- df[j,]$time - timeIRS[1]
} else if(df[j,]$time >= timeIRS[2]){
df$decayIRS <- df[j,]$time - timeIRS[2]
} else{
}
}
} else{
}
datm2 <- rbind(datm2, df)
}
## make difference from ITN intervention with current data
# change all datm2 to datm3 and all datm to datm2 and all IRS to ITN
datm3 <- NULL
for(i in levels(datm2$District)){
df <- subset(datm2, datm2$District %in% i)
timeITN <- df$time[df$ITNind==1]
df[, "decayITN"] <- NA
if(length(timeITN)==1){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeITN){
df[j,]$decayITN <- df[j,]$time - timeITN
}
}
} else if(length(timeITN)==2){
for(j in 1:dim(df)[1]){
if(df[j,]$time >= timeITN[1] & df[j,]$time < timeITN[2]){
df$decayITN <- df[j,]$time - timeITN[1]
} else if(df[j,]$time >= timeITN[2]){
df$decayITN <- df[j,]$time - timeITN[2]
} else{
}
}
} else{
}
datm3 <- rbind(datm3, df)
}
datm3$decayIRS <- 1 - datm3$decayIRS*(0.25/24)
datm3$decayITN <- 1 - datm3$decayITN*(0.4/96)
View(datm3)
View(datm3)
rm(list=ls())
inc <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/incidence.csv")
int <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/intervention.csv")
weather <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/weather.csv")
weather$X <- NULL # remove unnecessary X column
# ----------------------------------------------------- #
# don't know if need sepearate dataset for each lag
# might need to uncomment this code and comment out the code above and create new merged data
weather2 <- weather
weather2$epiweek <- weather2$epiweek + 2
names(weather2) <- c("epiweek2", "year2", "raint2", "tavg2", "rh2", "sd2", "psfc2", "district2")
weather4 <- weather
weather4$epiweek <- weather4$epiweek + 4
names(weather4) <- c("epiweek4", "year4", "raint4", "tavg4", "rh4", "sd4", "psfc4", "district4")
weather8 <- weather
weather8$epiweek <- weather8$epiweek + 8
names(weather8) <- c("epiweek8", "year8", "raint8", "tavg8", "rh8", "sd8", "psfc8", "district8")
# create indicator variable for weather ITNS were given as intervention
intITN <- int[, c(1, 4:5)]
intITN$ITNind <- ifelse(is.na(intITN$ITNyear), 0, 1)
# create indicator variable for weather IRS was given as intervention
intIRS <- int[, c(1:3)]
intIRS$IRSind <- ifelse(is.na(intIRS$IRSyear), 0, 1)
# merge these updatated intervention datasets with incidence datasets
datm1 <- merge(inc, intITN, by.x = c("Epiyear", "Epiweek", "DISTCODE"),
by.y = c("ITNyear", "ITNepiWeek", "DISTCODE"), all = TRUE)
datm2 <- merge(datm1, intIRS, by.x = c("Epiyear", "Epiweek", "DISTCODE"),
by.y = c("IRSyear", "IRSepiWeek", "DISTCODE"), all = TRUE)
# change the intervention indicator variable NAs to 0s
datm2$ITNind <- ifelse(is.na(datm2$ITNind), 0, 1)
datm2$IRSind <- ifelse(is.na(datm2$IRSind), 0, 1)
#-------------------------------------------------------#
# Might need to merge separate lagged weather datasets
datm3 <- merge(datm2, weather2, by.x = c("District", "Epiweek", "Epiyear"),
by.y = c("district2", "epiweek2", "year2"))
datm4 <- merge(datm3, weather4, by.x = c("District", "Epiweek", "Epiyear"),
by.y = c("district4", "epiweek4", "year4"))
datm5 <- merge(datm4, weather8, by.x = c("Distric", "Epiweek", "Epiyear"),
by.y = c("district8", "epiweek8", "year8"))
datm5 <- merge(datm4, weather8, by.x = c("District", "Epiweek", "Epiyear"),
by.y = c("district8", "epiweek8", "year8"))
View(datm5)
View(datm5)
# create an incidence variable
datm5$incid <- datm5$cases/datm5$u5total*1000
## Save merged data as csv so don't have to run all this again ##
write.csv(datm5, "~/Documents/CU AMC Fall 2017/BIOS6640/Project/CleanMerged.csv")
rm(list=ls())
# load cleaned and merged dataset
datm <- read.csv("~/Documents/CU AMC Fall 2017/BIOS6640/Project/CleanMerged.csv")
datm$X <- NULL # unnecessary X column
# why does my merged data only have 131 levels now instead of 142?
# 51876 observations?
sum(datm$IRSind) # 35
sum(datm$ITNind) # 141
